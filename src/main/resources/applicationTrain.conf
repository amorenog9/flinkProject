# Kafka Parameters (Lectura desde Anubis df)
KAFKA_TOPIC_IN = "messages_in"
KAFKA_DIRECTION_IN = "localhost:9092"
KAFKA_TOPIC_OUT = "messages_out"
KAFKA_DIRECTION_OUT = "localhost:9092"

# Delta Parameters - Donde almacenaremos los recursos de Delta
# Trenes
TRAIN_DIR = "/tmp/delta/train"  # /home/alex/Escritorio/TFM/delta/train
TRAIN_DIR_TABLE = "/tmp/delta/train/table" # /home/alex/Escritorio/TFM/delta/train/table
TRAIN_DIR_CHECKPOINT = "/tmp/delta/train/checkpoint" # /home/alex/Escritorio/TFM/delta/train/checkpoint
PATH_EVENTS_FROM_TIMESTAMP = "/tmp/events_from_timestamp"


TRAIN_DIR_2 = "/tmp/delta_2/train"  # /home/alex/Escritorio/TFM/delta/train
TRAIN_DIR_TABLE_2 = "/tmp/delta_2/train/table" # /home/alex/Escritorio/TFM/delta/train/table
TRAIN_DIR_CHECKPOINT_2 = "/tmp/delta_2/train/checkpoint" # /home/alex/Escritorio/TFM/delta/train/checkpoint

# System parameters - Train - Columnas del stream inicial de Kafka
nombreSistema = "Train Events System"
nombreEvento = "EVENT_TYPE"
fechaEvento = "DATE_EVENT"
idEvento = "ID"
latitudEvento = "LAT"
longitudEvento = "LNG"
localizacionEvento = "LOCATION_IDENTIFIED"

# Kafka Producers and consumers configuration (Python)
PATH_EVENTS_FROM_TIMESTAMP_KAFKA_PRODUCER = "/home/alex/Escritorio/TFM/streamer/kafka/TemporalStreamProducer.py" # Fichero que realiza el stream de los valores de la tabla a partir del timestamp seleccionado
TIMESTAMP_TOPIC_IN = "messages_from_timestamp_in"
TIMESTAMP_TOPIC_OUT = "messages_from_timestamp_out"
NOMBRE_SISTEMA_TIMESTAMP = "Events from Timestamp"

